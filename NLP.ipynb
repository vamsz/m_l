{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libarary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hope you are having a good week. Just checking in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>K..give back my thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Am also doing in cbe only. But have to pay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary 4 STAR Ibiza Holiday or å£10,000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail: Dear Dave this is your final notice to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>You are a great role model. You are giving so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Awesome, I remember the last time we got someb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>spam</td>\n",
       "      <td>If you don't, your prize will go to another cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>spam</td>\n",
       "      <td>SMS. ac JSco: Energy is high, but u may not kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Shall call now dear having food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5559 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               text\n",
       "0      ham  Hope you are having a good week. Just checking in\n",
       "1      ham                            K..give back my thanks.\n",
       "2      ham        Am also doing in cbe only. But have to pay.\n",
       "3     spam  complimentary 4 STAR Ibiza Holiday or å£10,000...\n",
       "4     spam  okmail: Dear Dave this is your final notice to...\n",
       "...    ...                                                ...\n",
       "5554   ham  You are a great role model. You are giving so ...\n",
       "5555   ham  Awesome, I remember the last time we got someb...\n",
       "5556  spam  If you don't, your prize will go to another cu...\n",
       "5557  spam  SMS. ac JSco: Energy is high, but u may not kn...\n",
       "5558   ham                    Shall call now dear having food\n",
       "\n",
       "[5559 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data set\n",
    "\n",
    "email_data = pd.read_csv(\"~/Downloads/Data Science/data set/ham_spam.csv\",encoding = \"ISO-8859-1\")\n",
    "email_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data \n",
    "import re\n",
    "stop_words = []\n",
    "with open(\"stop.txt\") as f:\n",
    "    stop_words = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the entire string by giving separator as \"\\n\" to get list of \n",
    "# all stop words\n",
    "stop_words = stop_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(i):\n",
    "    i = re.sub(\"[^A-Za-z\" \"]+\",\" \",i).lower()\n",
    "    i = re.sub(\"[0-9\" \"]+\",\" \",i)\n",
    "    w = []\n",
    "    for word in i.split(\" \"):\n",
    "        if len(word)>3:\n",
    "            w.append(word)\n",
    "    return (\" \".join(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope having good week just checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>give back thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>also doing only have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary star ibiza holiday cash needs yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail dear dave this your final notice collec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>great role model giving much really wish each ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>awesome remember last time somebody high first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>spam</td>\n",
       "      <td>your prize will another customer polo suite lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>spam</td>\n",
       "      <td>jsco energy high know where channel leadership...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>shall call dear having food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5559 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               text\n",
       "0      ham                hope having good week just checking\n",
       "1      ham                                   give back thanks\n",
       "2      ham                               also doing only have\n",
       "3     spam  complimentary star ibiza holiday cash needs yo...\n",
       "4     spam  okmail dear dave this your final notice collec...\n",
       "...    ...                                                ...\n",
       "5554   ham  great role model giving much really wish each ...\n",
       "5555   ham  awesome remember last time somebody high first...\n",
       "5556  spam  your prize will another customer polo suite lo...\n",
       "5557  spam  jsco energy high know where channel leadership...\n",
       "5558   ham                        shall call dear having food\n",
       "\n",
       "[5559 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data.text = email_data.text.apply(cleaning_text)\n",
    "email_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing empty rows \n",
    "email_data.shape\n",
    "email_data = email_data.loc[email_data.text != \" \",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a matrix of token counts for the entire text document \n",
    "\n",
    "def split_into_words(i):\n",
    "    return [word for word in i.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train and test data sets \n",
    "email_train,email_test = train_test_split(email_data,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function split_into_words at 0x11a051170>,\n",
       "                binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing email texts into word count matrix format \n",
    "emails_bow = CountVectorizer(analyzer=split_into_words).fit(email_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5559, 6661)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For all messages\n",
    "all_emails_matrix = emails_bow.transform(email_data.text)\n",
    "all_emails_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3891, 6661)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For training messages\n",
    "train_emails_matrix = emails_bow.transform(email_train.text)\n",
    "train_emails_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1668, 6661)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For testing messages\n",
    "test_emails_matrix = emails_bow.transform(email_test.text)\n",
    "test_emails_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.9889488563351324\n",
      "test accuracy 0.9760191846522782\n"
     ]
    }
   ],
   "source": [
    "# Preparing a naive bayes model on training data set \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB as MB\n",
    "from sklearn.naive_bayes import GaussianNB as GB\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "classifier_mb = MB()\n",
    "classifier_mb.fit(train_emails_matrix,email_train.type)\n",
    "train_pred_m = classifier_mb.predict(train_emails_matrix)\n",
    "accuracy_train_m = np.mean(train_pred_m==email_train.type)\n",
    "print(\"train accuracy\",accuracy_train_m)\n",
    "test_pred_m = classifier_mb.predict(test_emails_matrix)\n",
    "accuracy_test_m = np.mean(test_pred_m==email_test.type)\n",
    "print(\"test accuracy\",accuracy_test_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
